# Fine-tuning-GPT-2-for-melody-generation
Implement GPT-2 model from scratch as intructed in the book "LLM from scratch" by Sebastian Raschka, then create a new vocab, tokenizer and modify the model architecture for melody generation task. 
Dataset used for finetuning the model is Essen Folksong Database.
Full report will be updated soon, as development still in progress
